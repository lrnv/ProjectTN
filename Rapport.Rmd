---
title: "Projet de Techniques numériques : Estimation d'une provision pour dépréciation durable"
author: "LAVERNY Oskar, MARJOLET Pierre, BARRY Dieynaba"
date: "8 décembre 2017"
output:
  html_document:
    toc: true # table of content true
    toc_depth: 5  # upto five depths of headings (specified by #, ##, ###, #### and #####)
    number_sections: true  ## if you want number sections at each table header
---

```{r setup, include=FALSE}
####### Chunk permettant de set-up les paramètres par déffaut des chunk suivants. 
knitr::opts_chunk$set(echo = FALSE,
                      fig.align='center',
                      warning = FALSE,
                      fig.show='hold',
                      fig.width=11,
                      fig.height=5) # Par déffaut, le code n'est pas afficher mais les résultats ( les sorties) le seront. 

#### On en profite pour mettre en place les packages et les seeds.
library(knitr)
library(magrittr) 
library(dplyr)
# Les générateurs ont une version possible sans magrittr. peut-être qu'on rendra le projet sans ? Histoire de ne pas utiliser de packet, et de pouvoir dire qu'on a tout fait avec rbase. 
# A voir.
set.seed(100) # On fixe la seed pour la reproductibilité
M = 100 # On fixe un nombre de simulations par déffaut

# Jeux de paramètres utilisés :
# si vous souhaitez changer la valeur d'un paramètre, changez-la ici : l'écriture dans le papier sera elle aussi impactée. 
########## WARNING : POUR CITER UN PARAMETRE DANS LE PAPIER? CITEZ-LE PAR SA VALEUR ICI ET N'ECRIVEZ PAS LA VELUR EN DUR.
alpha = c(0.15,0.2) # par déffaut, alpha[1] est utilisé
naif=TRUE
S0=100
Sa=120
delta_t = 1/365
r=0.015
sigma=0.45
Temps = c(1,2,5,10,15,100) # par déffaut, Temps[1] est utilisé.
delta_theta=10^(-5)

### On source les générateurs (utiliser "setwd()" si besoin pour se mettre dans le bon dossier.)
source("Generateurs.R")
```


# Partie commentaire. (a supprimer avant de faire le rendu)


------------------------------------------------------------------------


Tout n'est pas encore fait. j'ai setup les différentes sections, mais ne vous génez pas pour les modifier si vous le souhaitez. Il y a beaucoup a rédiger, quelques graphes a sortir et tout. 

Le partage en deux fichiers ( un fichier générateur que l'on source) sera peut-être a supprimer aussi car YAHIA veut qu'on lui rende juste un raport et le code. On peut donc rendre un rapport ( le format compilé de ce fichier) et ce fichier ( non compile ). Il faudras donc copier dans le fichier le fichier générateur plutot que de le sourcer. Pour l'instant, on peut rester avec 2 fichier séparés, c'est plus simple de séparer les deux pour des question de gestion. 

Sur la partie 2 actifs, ils sont générés, mais l'étude est encore a faire. De plus je ne suis pas sur d'avoir bien compris ce qu'il voulait. 

Sur la partie un seul actif, il y a encore beacoup a faire aussi. Ne vous genez pas pour modifier ce que j'ai fait, c'est juste une base de travail pour l'instant ! 


------------------------------------------------------------------------


# Introduction


------------------------------------------------------------------------


Bla bla bla.
Ici il faudrait par exemple reprendre le sujet et reposer les dynamiques, les formules de lambda, les récurences, et la PDD au final, son actualisation, les méthode de rafinement par pont brownien, les calculs de sensibilité... La partie Maths quoi.

Raconter comment on a compris le sujet, histoire que si on c'est planter dans le code on s'en rendre peut-être compte ici.

**Approche de l'implémentation du problème :**

Pour implémenter le problème, nous avons considéré la PDD comme étant une variable aléatoire, et avons donc créé une fonction *rPDD* prenant en paramètres le nombre de simulations voulu ainsi que les différents paramètres du problème.
Ainsi, les algorithmes de Monte-Carlo se font juste par la moyenne des simulation, comme pour n'importe quelle variable aléatoire, ce qui est cohérent avec la manière dont R fonctionne. 
Le générateur est paramètré pour pouvoir utiliser un raffinement par *Ponts Browniens* ou non. L'implémentation des *Ponts Browniens* suit à la lettre ce qui a été fait en TD ainsi que le dans le cours.
La génération de deux actif corrélés s'appuie, de la même manière, sur une fonction *rPDD2* qui est juste une reprise du générateur de base avec des aléas corrélés via une implémentation de la solution de cholesky en dimention 2 vue en cours.

**Choix des paramètres par déffaut**

Pour l'ensemble des simulations, dans le cas où des re-paramètrages ne sont pas précisés, nous utiliserons les paramètres suivants par défaut : 

* $S0=`r S0`$, le prix de l'actif en 0.
* $Sa=`r Sa`$, la barrière.
* $\delta_t = \frac{1}{`r 1/delta_t`}$, le pas de discrétisation a l'interieur d'une periode.
* $T = `r paste(Temps,sep=",")`$, le nombre de periodes.
* $\alpha=`r paste(alpha,sep=",")`$, tel que $(1-\alpha)$ soit le seuil fixé dans l'énoncé.
* $r=`r r`$, le taux d'intéret.
* $\sigma=`r sigma`$, la volatilité du sous-jacent.
* $\Delta_\theta=`r delta_theta`$, la taille des différences finies.
* $M = `r M`$, le nombre de simulations de Monte-Carlo.


------------------------------------------------------------------------


# Un seul actif


------------------------------------------------------------------------


Dans le cadre du modèle posé supra, nous avons estimé la PDD, ainsi que la probabilité qu'elle soit positive, par une méthode de monté-carlo naive, ainsi que par une méthode dite *raffinée* inclunant un pont brownien entre les points de discrétisation. Le nombre de periodes, $T$, varie comme demandé dans l'énoncé.

**Teaser** : Deux graphs de densitée de la PDD pour une seule periode ($T=1$), avec les paramètres par défaut, avec ou sans pont brownien.


```{r graphs}
# Générateur de PDD :
par(mfrow=c(1,2))
rPDD(M,raffinement=FALSE) %>%
  density %>%
  plot(main="Densitée empirique de la PDD, méthode naive.",xlab = "x",ylab="f_{PDD}(x)")
rPDD(M,raffinement=TRUE) %>%
  density %>%
  plot(main="Densitée empirique de la PDD, méthode raffinée",xlab = "x",ylab="f_{PDD}(x)")
```



------------------------------------------------------------------------


## Estimation de la PDD


------------------------------------------------------------------------


L'estimation de la PDD se fait par Monte-Carlo. On génère la PDD comme une variable aléatoire, et la probabilité qu'elle soit positive est calculée ensuite par la méthode de Monte-Carlo.


------------------------------------------------------------------------


### Méthode naive


------------------------------------------------------------------------


La méthode naive consiste à considérer une génération de la valeur de l'actif en chaque point de discrétisation. Ainsi, la barrière sur les 6 derniers mois n'est pas calculée en continue, mais on utilise plutot une approximation par discrétisation simple, comme vu en cours. Cette méthode doit tendre à atteindre la barrière moins souvent qu'il faudrait, et implique donc un biais dans l'estimation. 

#### Description du travail

Ici on peut donner l'algorithme appliqué par le générateur, au moins l'agorithme naif. 


#### Résultats : 

**Les jeux de re-paramètrages suivants ont été utilisés : **

* $\alpha = `r alpha[1]`$ ou $\alpha = `r alpha[2]`$
* $T = `r paste(Temps,sep=",")`$


Pour $\alpha = `r alpha[1]`$, on obtient : 

```{r alpha0.2}

# Fonction de calcul des tableaux : 
to_apply_alpha <- function(alpha,rafinnement=FALSE){
    Temps %>% 
      lapply(function(x) {
        rPDD(M,raffinement=rafinnement,alpha=alpha,Temps=x) %>% 
          {data.frame(Moyenne = mean(.),ProbaPositif = mean(. > 0))} %>%
          return
        }) %>% 
      do.call(rbind,.) %>% 
      data.frame %>% 
      mutate(Rafiner = rep(ifelse(rafinnement,"Oui","Non"),length(Temps)),T = Temps) %>%
      {data.frame(.)[,c(4,1,2)]} %>%
      return
}

col.names=c("Temps T","PDD obtenue (MC)","Probabilité que la PDD soit positive")

alpha[1] %>% 
  to_apply_alpha %>%
  kable(col.names=col.names) # fonction d'affichage
```

Pour $\alpha = `r alpha[2]`$, on obtient :
```{r suite}
alpha[2] %>% 
  to_apply_alpha %>%
  kable(col.names=col.names) # fonction d'affichage

```

#### Analyse des Résultats : 

Ici il faut analyser les resultats.



------------------------------------------------------------------------


### Méthode raffinée par Pont brownien. 


------------------------------------------------------------------------


#### Description du travail

Ici on peut donner l'algorithme appliqué par le générateur, expliquer le raffinement par pont brownien,z


#### Résultats : 

Pour $\alpha = `r alpha[1]`$, on obtient : 

```{r alpha1.2}
alpha[1] %>% 
  to_apply_alpha(rafinnement = TRUE) %>%
  kable(col.names=col.names) # fonction d'affichage
```

Pour $\alpha = `r alpha[2]`$, on obtient :
```{r suite2}
alpha[2] %>% 
  to_apply_alpha(rafinnement = TRUE) %>%
  kable(col.names=col.names) # fonction d'affichage

```



#### Analyse des Résultats : 

Ici il faut analyser les resultats.




------------------------------------------------------------------------


## Sensibilité de la PDD : 


------------------------------------------------------------------------


On va passer aux calculs de sensibilité de la PDD par rapport a certains paramètres, par la méthode des différences finies. On va donc grapher une fonction qui, a un paramètre ($\sigma$, $r$, $S_0$ ou $S_a$) donné, associe la dérivée partielle de la PDD. 


**Les jeux de re-paramètrages suivants ont été utilisé : **

* $\alpha = `r alpha[2]`$
* $T = `r paste(Temps[1:2],sep=",")`$

### Par rapport à la valeur initiale $S_0$

```{r Greques_Delta}



plotting_greeks <- function(greque="Delta",naif=TRUE){
# Traçons nos deux graphiques : 
    par(mfrow=c(1,2))
      
    rGreek(n=M,
           greek=greque,
           alpha=alpha[2],
           Temps = Temps[1],
           raffinement = !naif) %>%   
      hist(main=paste0("Histograme de ",greque,ifelse(naif,", methode naive",", methode rafinnée"),",T=1"),
           xlab = "x",
           ylab="Frequency")
    
    
    rGreek(n=M,
           greek="Delta",
           alpha=alpha[2],
           Temps = Temps[2],
           raffinement = !naif) %>%   
      hist(main=paste0("Histograme de ",greque,ifelse(naif,", methode naive",", methode rafinnée"),",T=2"),
           xlab = "x",
           ylab="Frequency")
}


plotting_greeks()
plotting_greeks(naif=FALSE)

```


### Par rapport à la barrière $S_a$

```{r Greques_Saga}
plotting_greeks(greque="Saga",naif=TRUE)
plotting_greeks(greque="Saga",naif=FALSE)
```

### Par rapport au taux d'interet $r$

```{r Greques_Rho}
plotting_greeks(greque="Rho",naif=TRUE)
plotting_greeks(greque="Rho",naif=FALSE)
```



### Par rapport à la volatilité $\sigma$

```{r Greques_Vega}
plotting_greeks(greque="Vega",naif=TRUE)
plotting_greeks(greque="Vega",naif=FALSE)
```


### Résumé des dérivées obtenues : 

Par Monte-Carlo, en prenant la moyenne, on obtient les moyennes suivantes pour Delta,Saga,Rho et Vega, avec alpha = 2 et T = 1 ou 2.

```{r Greques_summary}

# on fait un petit summary des moyennes obtenues sous les diférents paramètrages : 

data.frame(Temp = c(1,1,2,2),
           Naif=c(TRUE,FALSE,TRUE,FALSE)) %>% group_by(Temp,Naif) %>%
  mutate(Delta = mean(rGreek(n=M,greek="Delta",alpha=alpha[2],Temps=Temp,raffinement=!Naif)),
         Saga = mean(rGreek(n=M,greek="Saga",alpha=alpha[2],Temps=Temp,raffinement=!Naif)),
         Rho = mean(rGreek(n=M,greek="Rho",alpha=alpha[2],Temps=Temp,raffinement=!Naif)),
         Vega = mean(rGreek(n=M,greek="Vega",alpha=alpha[2],Temps=Temp,raffinement=!Naif))
         ) %>%
  kable


```








------------------------------------------------------------------------


# Deux actifs 


------------------------------------------------------------------------


L'idée est de considérer deux actifs corrélés, avec un coefficient de corrélation $\rho \in {0,1,-0.3}$, et via l'algorithme de cholesky générer deux browniens corrélés puis générer sur chacun des browniens les deux actifs, et les deux PDD. 

On pourra étudier pour chaque modalité la corrélation entre les deux PDD. 

On pourra même si on se chauffe un peu chercher la copule asociée aux deux PDD en fonction du coefficient de corrélation :)



------------------------------------------------------------------------


## Algorythme de cholesky


------------------------------------------------------------------------


ici il faut décrire l'agorithme. 


------------------------------------------------------------------------


## Génération des deux PDD corrélées. 


------------------------------------------------------------------------



Exemple de code pour rho=1 : 
```{r PDD}
rPDD2(1000,rho=1) %>% data.frame %>% plot

```


Normal : L'aléa etant comonotone, i.e les deux actifs sont les mêmes, il aurait été bizarre de ne pas passer la même PDD.


pour rho=0 : 
```{r PDD2}
rPDD2(1000,rho=0) %>% data.frame %>% plot

```

Cette fois, on ne lit rien : ce qui est aussi bon signe, les PDD de deux actifs indépendants sont indépendantes.

pour rho = 0.9
```{r PDD3}
rPDD2(1000,rho=0.9) %>% data.frame %>% plot

```

Ici par contre on voit bien une corrélation positive entre deux actifs positivement corrélés. ça me parait logique mais j'ai pas plus creusé pour l'instant, a voir. 


### Principe 

ici décrire comment on re-calcule les PDD sur les actifs de manière jointe. 
En gros on fait exactement pareil qu'avant, mais on prend pour chaque actif l'aléa marginal (un des deux browniens corrélés)

### Applications

#### $\rho = 0$

#### $\rho = 1$

#### $\rho = -0.3$


------------------------------------------------------------------------


## Structure de dépendance obtenue


------------------------------------------------------------------------


Ici on va regarder, par exemple, le taux de kendal en fonction de \rho, le \rho de spearman en fonction de \rho, etc... 

On peut même construire nos browniens corrélés en fonction de leur \tau de kendall, et regarder comme évolue le taux de kendall des PDD en fonction du taux de kendall des browniens. 


### Sensibilité de la structure sur $\rho$

Là on cale les graphiques dont on vient de parler. 

### Sensibilité de la structure sur les autres paramètres. 
